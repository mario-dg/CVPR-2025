\begin{abstract}
Accurate single cell detection in brightfield microscopy is crucial for biological research, yet data scarcity and annotation bottlenecks limit the progress of deep learning methods.
We investigate the use of unconditional models to generate synthetic brightfield microscopy images and evaluate their impact on object detection performance.
A U-Net based diffusion model was trained and used to create datasets with varying ratios of synthetic and real images.
Experiments with YOLOv8, YOLOv9 and RT-DETR reveal that training with synthetic data can achieve improved detection accuracies (at minimal costs).
A human expert survey demonstrates the high realism of generated images, with experts not capable to distinguish them from real microscopy images (accuracy $\sim$50\%).
Our findings suggest that diffusion-based synthetic data generation is a promising avenue for augmenting real datasets in microscopy image analysis, reducing the reliance on extensive manual annotation and potentially improving the robustness of cell detection models.
\end{abstract}